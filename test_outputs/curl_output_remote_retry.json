{"status":"success","message":"Agent generated successfully","code":"import os\nfrom typing import Optional, List\nfrom huggingface_hub import InferenceClient, HfApi, ModelCard\n\nclass DeployedDbBot:\n    def __init__(self, api_key: Optional[str] = None):\n        \"\"\"\n        Initialize the DeployedDbBot agent.\n        \n        :param api_key: Hugging Face API token. If None, will try to get from HUGGINGFACEHUB_API_TOKEN env var.\n        \"\"\"\n        if api_key is None:\n            api_key = os.environ.get(\"HUGGINGFACEHUB_API_TOKEN\")\n        if not api_key:\n            raise ValueError(\"HUGGINGFACEHUB_API_TOKEN environment variable not set. Please set it in your .env file or environment.\")\n        self.client = InferenceClient(token=api_key)\n        self.api = HfApi(token=api_key)\n        self.prompt = \"You are a bot.\"\n        self.model = os.environ.get(\"HUGGINGFACE_MODEL\", \"meta-llama/Meta-Llama-3-8B-Instruct\")\n\n    def search_models(self, query: str, limit: int = 5) -> List[str]:\n        \"\"\"Searches for models on the Hugging Face Hub.\"\"\"\n        try:\n            models = self.api.list_models(search=query, limit=limit, sort=\"downloads\", direction=-1)\n            return [model.modelId for model in models]\n        except Exception as e:\n            raise RuntimeError(f\"Error searching models: {e}\")\n\n    def search_datasets(self, query: str, limit: int = 5) -> List[str]:\n        \"\"\"Searches for datasets on the Hugging Face Hub.\"\"\"\n        try:\n            datasets = self.api.list_datasets(search=query, limit=limit, sort=\"downloads\", direction=-1)\n            return [dataset.id for dataset in datasets]\n        except Exception as e:\n            raise RuntimeError(f\"Error searching datasets: {e}\")\n\n    def get_model_documentation(self, model_id: str) -> str:\n        \"\"\"Retrieves the Model Card (documentation) for a specific model.\"\"\"\n        try:\n            card = ModelCard.load(model_id)\n            return card.text\n        except Exception as e:\n            return f\"Error retrieving documentation for {model_id}: {e}\"\n\n    def get_api_endpoint(self, model_id: str) -> str:\n        \"\"\"Constructs the likely Inference API endpoint for a model.\"\"\"\n        return f\"https://api-inference.huggingface.co/models/{model_id}\"\n\n    def run(self, task: str, max_tokens: int = 1024) -> str:\n        \"\"\"\n        Run the agent with a given task.\n        \n        :param task: The task or question for the agent\n        :param max_tokens: Maximum tokens to generate (default: 1024)\n        :return: The agent's response\n        \"\"\"\n        messages = [\n            {\"role\": \"system\", \"content\": self.prompt},\n            {\"role\": \"user\", \"content\": task}\n        ]\n        \n        try:\n            \n            response = self.client.chat_completion(\n                model=self.model,\n                messages=messages,\n                max_tokens=max_tokens,\n                stream=False\n            )\n            if response and hasattr(response, 'choices') and response.choices:\n                message = response.choices[0].message\n                if message and hasattr(message, 'content'):\n                    return message.content\n            raise RuntimeError(\"Invalid response format from API\")\n            \n        except Exception as e:\n            raise RuntimeError(f\"Error calling Hugging Face API: {e}\")\n\nif __name__ == '__main__':\n    import os\n    import sys\n    import argparse\n    from dotenv import load_dotenv\n\n    load_dotenv()\n\n    # Parse command line arguments\n    parser = argparse.ArgumentParser(description=\"Run the DeployedDbBot agent.\")\n    parser.add_argument(\"--task\", default=\"Query the DB.\", help=\"The task to be performed by the agent\")\n    parser.add_argument(\"--search-model\", help=\"Search for a model documentation and analyze it\")\n    args = parser.parse_args()\n\n    # Ensure API key is set\n    api_key = os.environ.get(\"HUGGINGFACEHUB_API_TOKEN\")\n\n    try:\n        agent = DeployedDbBot(api_key=api_key)\n        \n        if args.search_model:\n            print(f\"Searching for model: {args.search_model}\")\n            try:\n                models = agent.search_models(args.search_model)\n                if models:\n                    top_model = models[0]\n                    print(f\"Found top model: {top_model}\")\n                    print(\"Fetching documentation...\")\n                    doc = agent.get_model_documentation(top_model)\n                    print(f\"--- Documentation for {top_model} ---\")\n                    print(doc[:500] + \"...\\n(truncated)\")\n                    print(\"---------------------------------------\")\n                    \n                    # Analyze with LLM\n                    analysis_task = f\"Summarize the capabilities and usage of this model based on its documentation: {doc[:2000]}\"\n                    print(\"Analyzing documentation with LLM...\")\n                    result = agent.run(analysis_task)\n                    print(\"\\nAnalysis Result:\")\n                    print(result)\n                else:\n                    print(\"No models found.\")\n            except Exception as e:\n                print(f\"Error during model search: {e}\")\n        else:\n            print(f\"Running DeployedDbBot with task: {args.task}\\n\")\n            result = agent.run(args.task)\n            print(\"Response:\")\n            print(\"-\" * 50)\n            \n            print(result)\n            \n            print(\"-\" * 50)\n    except ValueError as e:\n        print(f\"Configuration error: {e}\")\n        sys.exit(1)\n    except Exception as e:\n        print(f\"Error running agent: {e}\")\n        sys.exit(1)","filename":"deployeddbbot.py"}