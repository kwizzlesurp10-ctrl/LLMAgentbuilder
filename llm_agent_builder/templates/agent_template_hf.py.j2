"""
{{ agent_name }} - Hugging Face Agent
Generated by LLM Agent Builder
"""

import os
import json
from typing import Optional, Dict, Any, List
{% if stream %}
from typing import Iterator
{% endif %}
import requests

class {{ agent_name }}:
    """
    {{ description }}
    
    This agent uses Hugging Face's Inference API.
    """
    
    def __init__(
        self,
        api_key: Optional[str] = None,
        model: str = "{{ model }}",
        temperature: float = {{ temperature }},
        max_tokens: int = {{ max_tokens }},
        system_prompt: Optional[str] = None
    ):
        """
        Initialize the {{ agent_name }}.
        
        Args:
            api_key: Hugging Face API key (or set HF_API_KEY environment variable)
            model: Model identifier on Hugging Face
            temperature: Sampling temperature
            max_tokens: Maximum tokens to generate
            system_prompt: System prompt to set agent behavior
        """
        self.api_key = api_key or os.getenv("HF_API_KEY")
        if not self.api_key:
            raise ValueError("Hugging Face API key must be provided or set in HF_API_KEY environment variable")
        
        self.model = model
        self.temperature = temperature
        self.max_tokens = max_tokens
        self.system_prompt = system_prompt or "{{ system_prompt }}"
        self.conversation_history: List[Dict[str, str]] = []
        
        # Hugging Face API endpoint
        self.api_url = f"https://api-inference.huggingface.co/models/{self.model}"
        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
    
    def _prepare_messages(self, user_message: str) -> List[Dict[str, str]]:
        """Prepare messages for the API call."""
        messages = [{"role": "system", "content": self.system_prompt}]
        messages.extend(self.conversation_history)
        messages.append({"role": "user", "content": user_message})
        return messages
    
    {% if stream %}
    def chat(self, message: str, stream: bool = True) -> Iterator[str]:
        """
        Send a message and get a streaming response.
        
        Args:
            message: User message
            stream: Whether to stream the response (always True for this method)
            
        Yields:
            Response chunks as they arrive
        """
        messages = self._prepare_messages(message)
        
        payload = {
            "inputs": self._format_messages(messages),
            "parameters": {
                "temperature": self.temperature,
                "max_new_tokens": self.max_tokens,
                "return_full_text": False
            },
            "stream": True
        }
        
        try:
            response = requests.post(
                self.api_url,
                headers=self.headers,
                json=payload,
                stream=True
            )
            response.raise_for_status()
            
            full_response = ""
            for line in response.iter_lines():
                if line:
                    try:
                        data = json.loads(line.decode('utf-8'))
                        if isinstance(data, list) and len(data) > 0:
                            chunk = data[0].get("generated_text", "")
                            if chunk:
                                full_response += chunk
                                yield chunk
                    except json.JSONDecodeError:
                        continue
            
            # Save to history
            self.conversation_history.append({"role": "user", "content": message})
            self.conversation_history.append({"role": "assistant", "content": full_response})
            
        except Exception as e:
            raise RuntimeError(f"Error calling Hugging Face API: {e}")

    {% else %}
    def chat(self, message: str) -> str:
        """
        Send a message and get a complete response.
        
        Args:
            message: User message
            
        Returns:
            Complete response from the agent
        """
        messages = self._prepare_messages(message)
        
        payload = {
            "inputs": self._format_messages(messages),
            "parameters": {
                "temperature": self.temperature,
                "max_new_tokens": self.max_tokens,
                "return_full_text": False
            }
        }
        
        try:
            response = requests.post(
                self.api_url,
                headers=self.headers,
                json=payload
            )
            response.raise_for_status()
            
            result = response.json()
            if isinstance(result, list) and len(result) > 0:
                assistant_message = result[0].get("generated_text", "")
            else:
                assistant_message = str(result)
            
            # Save to history
            self.conversation_history.append({"role": "user", "content": message})
            self.conversation_history.append({"role": "assistant", "content": assistant_message})
            
            return assistant_message
            
        except Exception as e:
            raise RuntimeError(f"Error calling Hugging Face API: {e}")

    {% endif %}
    
    def _format_messages(self, messages: List[Dict[str, str]]) -> str:
        """Format messages for Hugging Face API."""
        formatted = ""
        for msg in messages:
            role = msg["role"]
            content = msg["content"]
            if role == "system":
                formatted += f"System: {content}\n"
            elif role == "user":
                formatted += f"User: {content}\n"
            elif role == "assistant":
                formatted += f"Assistant: {content}\n"
        formatted += "Assistant: "
        return formatted
    
    def reset_conversation(self):
        """Reset the conversation history."""
        self.conversation_history = []

def main():
    """Example usage of {{ agent_name }}."""
    agent = {{ agent_name }}()
    
    print("{{ agent_name }} initialized!")
    print("Type 'quit' to exit, 'reset' to clear conversation history")
    print("-" * 50)
    
    while True:
        user_input = input("\nYou: ").strip()
        
        if user_input.lower() == 'quit':
            break
        
        if user_input.lower() == 'reset':
            agent.reset_conversation()
            print("Conversation history cleared!")
            continue
        
        if not user_input:
            continue
        
        print("\n{{ agent_name }}:", end=" ", flush=True)
        {% if stream %}
        for chunk in agent.chat(user_input):
            print(chunk, end="", flush=True)
        print()  # New line after streaming
        {% else %}
        result = agent.chat(user_input)
        print(result)
        {% endif %}
        print("-" * 50)

if __name__ == "__main__":
    main()
